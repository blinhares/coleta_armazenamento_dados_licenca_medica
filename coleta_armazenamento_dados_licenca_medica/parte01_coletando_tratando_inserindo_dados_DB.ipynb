{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from mysql import connector as cn #pip install mysql-connector-python\n",
    "import datetime \n",
    "from rich.jupyter import print\n",
    "\n",
    "\n",
    "#Conection Data:\n",
    "CON_DATA = {\n",
    "       'user':'db_med',\n",
    "       'password': 'db_med',\n",
    "       'host': '127.0.0.1',\n",
    "       'database' : 'db_med'\n",
    "       }\n",
    "\n",
    "#Pasta de Origem\n",
    "PATH_TO_TESTE = '/home/bruno/Documentos/Python/projetos_python/Estudos/XP_MOD5/BootCampArquBigData/Mod02/trabalho_pratic/src/extracted_data/2020-01-01.csv'\n",
    "\n",
    "PATH = '/home/bruno/Documentos/Python/projetos_python/estudos/XP_MOD5/BootCampArquBigData/Desafio/src/processamento_licencas_medicas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo Arquivos, Transformando em DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Iniciando a coleta de dados de Licenças Medicas...', end='')\n",
    "\n",
    "arquivos_lidos = []\n",
    "for file in Path(PATH).iterdir():\n",
    "    if file.name.endswith('csv'):\n",
    "        # print(f'+ {file.name} aos dados...')\n",
    "        arquivos_lidos.append(pd.read_csv(Path(file).as_posix(),sep='|', encoding= 'ISO-8859-1'))\n",
    "print('[green]OK')\n",
    "print('Criando DF...', end='')\n",
    "\n",
    "df = pd.concat(arquivos_lidos)\n",
    "del arquivos_lidos\n",
    "print('[green]OK')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenchendo dados Faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Seram substituidas {df['salario'].isnull().sum()} observacoes...\")\n",
    "df['salario'] = df['salario'].fillna(df['salario'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QTD Filhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Seram substituidas {df['qtd_filhos'].isnull().sum()} observacoes...\")\n",
    "df['qtd_filhos'] = df['qtd_filhos'].fillna(\n",
    "    round(df['qtd_filhos'].mean())\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resetando o Index, Eliminando Duplicados e Nulos/Vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "print(f'Seram [red]eliminanods {df.duplicated().sum()}[/red] dados duplicados.')\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'Seram [red]eliminados {sum(df.isna().sum().values)}[/red] dados nulos/ausentes')\n",
    "df.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banco de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectando ao Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = cn.connect(**CON_DATA) # tambem se pode utilizar com o with para evitar problemas\n",
    "# with cn.connect(**CON_DATA) as cnx:\n",
    "    # pass \n",
    "\n",
    "if cnx.is_connected():\n",
    "    print('Conexão Realizada com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo Funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserir_df_em_db(conector,tabela_destino,df:pd.DataFrame):\n",
    "    colunas = '`' + '`, `'.join(df.columns.values) + '`'\n",
    "    for i in range(df.count().values[0]):\n",
    "        conteudo = \"'\" + \"', '\".join([str(item) for item in df.loc[i].values]) + \"'\"\n",
    "\n",
    "        texto = f'Inserindo linha {i} : {conteudo}... '\n",
    "        \n",
    "        with conector.cursor() as cursor:\n",
    "            comando = f'''\n",
    "            INSERT INTO {tabela_destino} ({colunas}) VALUES ({conteudo});\n",
    "            '''\n",
    "            try:\n",
    "\n",
    "                cursor.execute(comando)\n",
    "                conector.commit() #confirmando as alteracoes\n",
    "                cursor.close()\n",
    "\n",
    "            except:\n",
    "\n",
    "                print(f'{texto}[red]Erro')\n",
    "                \n",
    "def get_data_from_table(conector, nome_tabela):\n",
    "    dicionario = dict()\n",
    "    with conector.cursor() as cursor:\n",
    "        result = cursor.execute(F'''SELECT * FROM {nome_tabela};''')\n",
    "        rows = cursor.fetchall()\n",
    "        for key, value in rows:\n",
    "            dicionario[value] = key\n",
    "        cursor.close()\n",
    "    return dicionario\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserindo Dados Primarios no DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux['estado'] = df['estado_colaborador'].unique()\n",
    "inserir_df_em_db(cnx, 'tb_estado', df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_estado no DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = get_data_from_table(cnx,'tb_estado')\n",
    "df['cod_estado'] = df['estado_colaborador'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estado-Civil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux['estado_civil'] = df['estado_civil'].unique()\n",
    "inserir_df_em_db(cnx, 'tb_estado_civil', df_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_estado_civil no DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = get_data_from_table(cnx,'tb_estado_civil')\n",
    "df['cod_estado_civil'] = df['estado_civil'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux['escolaridade'] = df['escolaridade'].unique()\n",
    "inserir_df_em_db(cnx, 'tb_escolaridade', df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_escolaridade no DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = get_data_from_table(cnx,'tb_escolaridade')\n",
    "df['cod_escolaridade'] = df['escolaridade'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hobbie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux['hobbie'] = df['hobbie'].unique()\n",
    "inserir_df_em_db(cnx, 'tb_hobbie', df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_hobbie no DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = get_data_from_table(cnx,'tb_hobbie')\n",
    "df['cod_hobbie'] = df['hobbie'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especialidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux['especialidade'] = df['especialidade'].unique()\n",
    "inserir_df_em_db(cnx, 'tb_especialidade', df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_especialidade no DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = get_data_from_table(cnx,'tb_especialidade')\n",
    "df['cod_especialidade'] = df['especialidade'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivo Licensa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux['motivo_licenca'] = df['motivo_licenca'].unique()\n",
    "inserir_df_em_db(cnx, 'tb_motivo_licenca', df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_licenca no DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = get_data_from_table(cnx,'tb_motivo_licenca')\n",
    "df['cod_motivo_licenca'] = df['motivo_licenca'].map(dict_encode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados Secundarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux = df[['nome_medico','cod_especialidade']].drop_duplicates()\n",
    "df_aux = df_aux.reset_index()\n",
    "df_aux.drop(['index'], axis=1, inplace=True)\n",
    "inserir_df_em_db(cnx, 'tb_medico', df_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no cod_medico no DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = dict()\n",
    "\n",
    "with cnx.cursor() as cursor:\n",
    "        result = cursor.execute(F'''SELECT cod_medico, nome_medico FROM {'tb_medico'};''')\n",
    "        rows = cursor.fetchall()\n",
    "        for key, value in rows:\n",
    "            dict_encode[value] = key\n",
    "df['cod_medico'] = df['nome_medico'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colaborador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.DataFrame()\n",
    "df_aux = df[['nome_colaborador','data_nascimento',\n",
    "            'sexo_colaborador',\n",
    "            'salario',\n",
    "            'qtd_filhos',\n",
    "            'possui_pet',\n",
    "            'cod_estado_civil',\n",
    "            'cod_escolaridade',\n",
    "            'cod_hobbie',\n",
    "            'cod_estado']].drop_duplicates()\n",
    "#remover nomes  duplicados\n",
    "df_aux[ df_aux['nome_colaborador'].duplicated().map(lambda x : not x)].count()\n",
    "\n",
    "df_aux = df_aux.reset_index()\n",
    "df_aux.drop(['index'], axis=1, inplace=True)\n",
    "inserir_df_em_db(cnx, 'tb_colaborador', df_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo cod_colaborador no DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_encode = dict()\n",
    "\n",
    "with cnx.cursor() as cursor:\n",
    "        result = cursor.execute(F'''SELECT cod_colaborador, nome_colaborador FROM {'tb_colaborador'};''')\n",
    "        rows = cursor.fetchall()\n",
    "        for key, value in rows:\n",
    "            dict_encode[value] = key\n",
    "df['cod_colaborador'] = df['nome_colaborador'].map(dict_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento Licenca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserindo no Banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como n tem uma chave unica que limiete os dados como um documetno ou algo \n",
    "# deve-se ter cuidado pra n dublicar os dados\n",
    "dados = False\n",
    "if dados:\n",
    "    df_aux = pd.DataFrame()\n",
    "    df_aux = df[['data_processamento','inicio_licenca',\n",
    "                'fim_licenca',\n",
    "                'duracao_licenca',\n",
    "                'cod_colaborador',\n",
    "                'cod_medico',\n",
    "                'cod_motivo_licenca']]\n",
    "    #resetar index por precaucao\n",
    "    df_aux = df_aux.reset_index()\n",
    "    df_aux.drop(['index'], axis=1, inplace=True)\n",
    "    inserir_df_em_db(cnx, 'tb_processamento_licenca', df_aux)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
